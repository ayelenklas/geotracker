{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle zip code list\n",
    "with open('../geotracker/data/zip.pkl', 'rb') as f:\n",
    "    zip_codes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.lieferando.de/en/delivery/food/berlin-10115'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create iterable list of URLS for the scraper\n",
    "base_url = \"https://www.lieferando.de/en/delivery/food/berlin-\"\n",
    "urls = [base_url + zip_code for zip_code in zip_codes]\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant page overview for each ZIP Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down():\n",
    "    \"\"\"A method for scrolling the page.\"\"\"\n",
    "\n",
    "    # Get scroll height.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Scroll down to the bottom.\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the page.\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height.\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        if new_height == last_height:\n",
    "\n",
    "            break\n",
    "\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set selenium options\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless\")  # Starts driver without opening a window\n",
    "driver = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Extract the information for restaurants from this page\n",
    "\n",
    "driver.get(urls[0])\n",
    "time.sleep(10)\n",
    "scroll_down()\n",
    "#names = driver.find_elements(by=By.CLASS_NAME, value='restaurantname notranslate')\n",
    "#names = driver.find_elements(By.CSS_SELECTOR, \"h3\")\n",
    "restaurants_names = driver.find_elements(By.XPATH, \"//a[@class='restaurantname notranslate']\")\n",
    "\n",
    "restaurant_urls = []\n",
    "restaurant_names = []\n",
    "for restaurant in restaurants_names:\n",
    "    restaurant_urls.append(restaurant.get_attribute(\"href\"))\n",
    "    restaurant_names.append(restaurant.text)\n",
    "\n",
    "print(restaurant_urls)\n",
    "print(restaurant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(restaurant_names))\n",
    "print(len(restaurant_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = driver.find_elements(By.CLASS_NAME, \"review_rating\")\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restaurants = driver.find_elements(By.XPATH, \"//h2[@class='restaurantname']\")\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all(\"div\", class_=\"review-rating\")\n",
    "print(len(reviews))\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating_attribute):\n",
    "    found = re.search(r\"[0-9]{1,3}\", rating_attribute)\n",
    "    return int(found[0]) / 20\n",
    "    \n",
    "convert_rating('width: 100%;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_reviews = reviews[ :len(restaurants_names)] # Remove the last element in the list which does not contain a review\n",
    "restaurant_reviews = []\n",
    "for clean_review in clean_reviews:\n",
    "    rating = clean_review.find(\"span\").get(\"style\")\n",
    "    restaurant_reviews.append(convert_rating(rating))\n",
    "    \n",
    "len(restaurant_reviews)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ratings = soup.find_all(\"span\", class_=\"rating-total\")\n",
    "clean_ratings = total_ratings[ :len(restaurants_names)]\n",
    "\n",
    "restaurant_rating_totals = []\n",
    "for clean_rating in clean_ratings:\n",
    "    total_rating = clean_rating.text.strip()\n",
    "    total_rating = re.search(r\"[0-9]{1,5}\", total_rating)[0]\n",
    "    restaurant_rating_totals.append(int(total_rating))\n",
    "\n",
    "print(len(restaurant_rating_totals))\n",
    "restaurant_rating_totals[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchens = soup.find_all(\"div\", class_=\"kitchens\")\n",
    "clean_kitchens = kitchens[ :len(restaurant_names)]\n",
    "\n",
    "restaurant_kitchens = []\n",
    "for clean_kitchen in clean_kitchens:\n",
    "    restaurant_kitchens.append(clean_kitchen.find(\"span\").text)\n",
    "    \n",
    "len(restaurant_kitchens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final restaurant list\n",
    "\n",
    "restaurant_list = []\n",
    "for restaurant_name, restaurant_url, restaurant_review, restaurant_rating_total, restaurant_kitchen in zip(restaurant_names, restaurant_urls, restaurant_reviews, restaurant_rating_totals, restaurant_kitchens):\n",
    "    restaurant_list.append(\n",
    "        dict(restaurant_name=restaurant_name,\n",
    "             restaurant_url=restaurant_url, \n",
    "             restaurant_review=restaurant_review, \n",
    "             restaurant_rating_total=restaurant_rating_total, \n",
    "             restaurant_kitchen=restaurant_kitchen)\n",
    "    )\n",
    "    \n",
    "restaurant_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from the restaurant pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.jsm:181:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.jsm:393:5\nelement.find/</<@chrome://remote/content/marionette/element.js:299:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2v/75hdky1j1xv5mw9hmtz1l2140000gq/T/ipykernel_32511/226655660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestaurant_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"restaurant_url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m wait.until(ec.visibility_of_element_located(\n\u001b[0m\u001b[1;32m      4\u001b[0m     (By.XPATH, \"//button[@class='info info-icon js-open-info-tab']\")))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/geotracker/lib/python3.8/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.jsm:181:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.jsm:393:5\nelement.find/</<@chrome://remote/content/marionette/element.js:299:16\n"
     ]
    }
   ],
   "source": [
    "driver.get(restaurant_list[0].get(\"restaurant_url\"))\n",
    "wait = WebDriverWait(driver, 15)\n",
    "wait.until(ec.visibility_of_element_located(\n",
    "    (By.XPATH, \"//button[@class='info info-icon js-open-info-tab']\")))\n",
    "\n",
    "\n",
    "button = driver.find_element(By.XPATH, \"//button[@class='info info-icon js-open-info-tab']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = driver.find_element(By.XPATH, \"//section[@class='card-body notranslate']\").text\n",
    "\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract street, ZIP code and City from string\n",
    "street = re.search(r\".*\", address)[0]\n",
    "zip_code = re.search(r\"[0-9]{5}\", address)[0]\n",
    "city = re.search(r\"[\\w]+$\", address)[0]\n",
    "\n",
    "print(\"street:\", street)\n",
    "print(\"zip code:\", zip_code)\n",
    "print(\"city:\", city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_rest_list = restaurant_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_rest_list[0][\"street\"] = street\n",
    "copy_rest_list[0][\"zip_code\"] = zip_code\n",
    "copy_rest_list[0][\"city\"] = city\n",
    "\n",
    "copy_rest_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(restaurant_list)\n",
    "df.drop_duplicates(subset=['restaurant_url'], inplace=True)\n",
    "restaurant_urls = df[\"restaurant_url\"]\n",
    "\n",
    "list(restaurant_urls)\n",
    "for index, url in restaurant_urls:\n",
    "    print(index, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff that didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_costs = soup.find_all(\"div\", class_=\"delivery-cost js-delivery-cost notranslate\")\n",
    "len(delivery_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_times = soup.find_all(\"div\", class_=\"avgdeliverytime avgdeliverytimefull open\")\n",
    "\n",
    "restaurant_delivery_times = [item.text for item in delivery_times]\n",
    "\n",
    "len(restaurant_delivery_times) # Different because it's empty for restaurants that are closed for delivery or closed right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_delivery_cost = [item.text for item in delivery_costs]\n",
    "print(len(restaurant_delivery_cost)) \n",
    "set(restaurant_delivery_cost) # unique Delivery costs don't include \"Free\"\n",
    "\n",
    "# Excludes restaurants where delivery is free and which are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_wrapper = soup.find_all(\"div\", class_=\"detailswrapper\")\n",
    "\n",
    "restaurant_wrapper[0]\n",
    "\n",
    "# This just contains skeleton code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking whether pickled files are okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../geotracker/data/restaurant_list_pickles/restaurant_list_7.pkl', 'rb') as f:\n",
    "    restaurant_list = pickle.load(f)\n",
    "    \n",
    "len(restaurant_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../raw_data/lieferando_pickles/city_lists/city_list_1640.pkl', 'rb') as f:\n",
    "    city_list = pickle.load(f)\n",
    "    \n",
    "len(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Berlin    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(city_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../raw_data/lieferando_pickles/zip_code_lists/zip_code_list_1640.pkl', 'rb') as f:\n",
    "    zip_code_list = pickle.load(f)\n",
    "    \n",
    "len(zip_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62497"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../raw_data/lieferando_pickles/restaurant_lists/restaurant_list_189.pkl', 'rb') as f:\n",
    "    restaurant_list = pickle.load(f)\n",
    "    \n",
    "len(restaurant_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.lieferando.de/en/menu/burger-king-berlin-schoenhauser-allee'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_list[0][\"restaurant_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3322"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [item[\"restaurant_url\"] for item in restaurant_list]\n",
    "\n",
    "len(set(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10437    46\n",
       "10117    39\n",
       "10119    38\n",
       "10178    28\n",
       "10435    23\n",
       "         ..\n",
       "12347     1\n",
       "10965     1\n",
       "13187     1\n",
       "13088     1\n",
       "13407     1\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(zip_code_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../raw_data/lieferando_pickles/street_lists/street_list_1640.pkl', 'rb') as f:\n",
    "    street_list = pickle.load(f)\n",
    "    \n",
    "len(street_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europaplatz 1             9\n",
       "Badstraße 4               7\n",
       "Schönhauser Allee 80      5\n",
       "Leipziger Platz 12        5\n",
       "Oranienburger Straße 7    2\n",
       "                         ..\n",
       "Müllerstraße 129          1\n",
       "Torstraße 129             1\n",
       "Erich-Weinert-Straße 1    1\n",
       "Weinbergsweg 8            1\n",
       "Wörther Straße 24         1\n",
       "Length: 484, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(street_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'threading' has no attribute 'csv_writer_lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2v/75hdky1j1xv5mw9hmtz1l2140000gq/T/ipykernel_32511/2603243894.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_writer_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'threading' has no attribute 'csv_writer_lock'"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "threading.csv_writer_lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zip_codes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37803fb805524fdccba396a39b7f0f988aa9f20b89dae5d95057c5414e00d75e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('geotracker': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
